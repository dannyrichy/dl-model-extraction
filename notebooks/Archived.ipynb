{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1GP5NutrOin"
   },
   "source": [
    "\n",
    "# Archived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "querytestloader =  query_victim(victim, outputs, testloader, len(testloader.dataset))\n",
    "sampledtrainloader = query_type(victim, outputs, trainloader, query_size,\n",
    "                                'queried/query_traindata_cifar10_resenet50', query_type)\n",
    "victim_model = fetch_victim_model(args=victim)\n",
    "\n",
    "def attacker_training_w_logits(victim_model, attacker_model, sampledtrainloader, querytestloader, k):\n",
    "    # initialize score lists\n",
    "    train_acc = []\n",
    "    train_loss = []\n",
    "    test_acc = []\n",
    "    test_loss = []\n",
    "    train_loss_func = None\n",
    "    \n",
    "    # select optimiser and scheduler\n",
    "    optimizer = torch.optim.Adam(attacker_model.parameters(), lr=config[\"learning_rate\"])\n",
    "    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=config[\"base_lr\"], max_lr=config[\"max_lr\"],\n",
    "                                                  step_size_up=config[\"lr_steps\"], mode='triangular2', cycle_momentum=False)\n",
    "\n",
    "    # select loss\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    # train for epochs\n",
    "    epochs = int(2*config[\"lr_cycles\"]*config[\"lr_steps\"]/(len(train_loader.dataset)/config[\"batch_size\"]))\n",
    "    print(f'Total epochs: {epochs}')\n",
    "    for epoch in range(epochs):\n",
    "        print(\"\\repoch\", epoch + 1)\n",
    "        \n",
    "        # train on Train Data\n",
    "        num_train = 0\n",
    "        num_correct_train = 0\n",
    "        attacker_model.train() \n",
    "        for (xList, _) in sampledtrainloader:\n",
    "            xList = torch.autograd.Variable(xList)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                xList = xList.type(torch.cuda.FloatTensor)\n",
    "                device = torch.device(DEVICE)\n",
    "                attacker_model.to(device)\n",
    "            \n",
    "            # query victim for logits\n",
    "            yList = victim_model(xList)\n",
    "            val, ind = torch.topk(yList, k, dim=1)\n",
    "            ones = (torch.ones(yList.shape)*float('-inf'))\n",
    "            if torch.cuda.is_available():\n",
    "                ones = ones.type(torch.cuda.FloatTensor)\n",
    "            yList = ones.scatter_(1, ind, val)\n",
    "            yList = torch.nn.functional.softmax(yList, dim=1)\n",
    "            \n",
    "            # get outputs and train model\n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs = attacker_model(xList)\n",
    "                train_loss_func = loss(outputs, yList)\n",
    "                train_loss_func.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "            # get correct predictions count\n",
    "            num_train += len(yList)\n",
    "            predicts = torch.max(outputs.data, 1)[1]\n",
    "            num_correct_train += (predicts == yList).float().sum()\n",
    "\n",
    "            print('\\r %d ...' % num_train, end='')\n",
    "\n",
    "        train_acc.append(num_correct_train / num_train)\n",
    "        train_loss.append(train_loss_func.data)\n",
    "        print(\"\\r    - train_acc %.5f train_loss %.5f\" % (train_acc[-1], train_loss[-1]))\n",
    "\n",
    "        # evaluate on Test Data\n",
    "        num_test = 0\n",
    "        num_correct_test = 0\n",
    "        attacker_model.eval()\n",
    "        for (xList, yList) in queriedtestloader:\n",
    "            if torch.cuda.is_available():\n",
    "                xList = xList.type(torch.cuda.FloatTensor)\n",
    "                yList = yList.type(torch.cuda.LongTensor)\n",
    "                device = torch.device(DEVICE)\n",
    "                attacker_model.to(device)\n",
    "            \n",
    "            #  get outputs\n",
    "            with torch.set_grad_enabled(False):\n",
    "                outputs = attacker_model(xList)\n",
    "                test_loss_func = loss(outputs, yList)\n",
    "            \n",
    "            # get correct predictions count\n",
    "            num_test += len(yList)\n",
    "            predicts = torch.max(outputs.data, 1)[1]\n",
    "            num_correct_test += (predicts == yList).float().sum()\n",
    "\n",
    "        test_acc.append(num_correct_test / num_test)\n",
    "        test_loss.append(test_loss_func.data)\n",
    "        print(\"\\r    - test_acc  %.5f test_loss  %.5f\" %(test_acc[-1], test_loss[-1]))\n",
    "    return train_loss, train_acc, test_loss, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train using entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, testloader, outputs = get_dataloader(config[\"victim\"][\"data\"])\n",
    "model = get_model(config[\"attacker\"], outputs)\n",
    "result = training(model, trainloader, testloader, config[\"epochs\"],\n",
    "                           optimizer=torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"]),\n",
    "                           loss=torch.nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Time outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.autograd.profiler.profile(use_cuda=True) as prof:\n",
    "    qtl = QueryVictim(trainloader, 1000, sampling='coreset_cross')\n",
    "print(f'Query Time:{prof.key_averages().self_cpu_time_total/1e6}s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize random Images from CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['air_plane', 'car', 'bird', 'cat',\n",
    "               'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "# get some random training images\n",
    "plt.figure(figsize=(10, 10))\n",
    "counter = 0\n",
    "for images, labels in trainloader:\n",
    "    for i, img in enumerate(images):\n",
    "        plt.subplot(5, 5, counter+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        img = img/2 + 0.5   # unmornalize\n",
    "        # convert (C,H,W) to (H,W,C)\n",
    "        img_show = np.transpose(img, (1, 2, 0))\n",
    "        plt.imshow(img_show, cmap=plt.cm.binary)\n",
    "        plt.xlabel(class_names[int(labels[i])], color='red', fontsize='large')\n",
    "        counter += 1\n",
    "        if counter == 25:\n",
    "            break\n",
    "    if counter == 25:\n",
    "        break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fo-AfuHO35n4"
   },
   "source": [
    "Load Victim from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4IzV4WCs34yX"
   },
   "outputs": [],
   "source": [
    "victim = ResNet34(3, ResBlock, outputs=10)\n",
    "victim.load_state_dict(torch.load('Victim_resnet34'))\n",
    "victim.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config Archived"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0aef49",
   "metadata": {},
   "source": [
    "import torch\n",
    "\n",
    "from victim.__init__ import *\n",
    "\n",
    "config = {\n",
    "    \"batch_size\": 500,\n",
    "    \"learning_rate\": 0.008,\n",
    "    \"epochs\": 80,\n",
    "    \"query_size\":5000,\n",
    "    \"query_type\": 'random',\n",
    "    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \"victim\": { \"data\": CIFAR_100,  \"model_name\": RESNET_56 },\n",
    "    \"attacker\": RESNET50\n",
    "}\n",
    "\n",
    "parameters = {\n",
    "        \"query_size\": [20000],\n",
    "        \"query_type\": ['random','coreset', 'coreset_cross'],\n",
    "        \"victim\":[{ \"data\": CIFAR_10, \"model_name\": RESNET50}],\n",
    "        \"attacker\": [RESNET34]\n",
    "}\n",
    "\n",
    "# Parameter Runs\n",
    "\n",
    "## Best Query Type, Best Query sizes on 2 datasets\n",
    "\n",
    "### Run1 - CIFAR10 - A_RESNET34 - V_RESNET50\n",
    "\n",
    "config = {\n",
    "    \"batch_size\": 500,\n",
    "    \"learning_rate\": 0.008,\n",
    "    \"epochs\": 100,\n",
    "    \"query_size\":5000,\n",
    "    \"query_type\": 'coreset',\n",
    "    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \"victim\": { \"data\": CIFAR_100,  \"model_name\": RESNET_56 }\n",
    "}\n",
    "\n",
    "parameters = {\n",
    "        \"query_size\": [10000, 20000, 30000, 40000, 50000],\n",
    "        \"query_type\": ['random', 'coreset', 'coreset_cross'],\n",
    "        \"victim\":[{ \"data\": CIFAR_10,  \"model_name\": RESNET50}]\n",
    "}\n",
    "\n",
    "### Run2 - CIFAR10 - A_RESNET34 - V_RESNET50\n",
    "\n",
    "config = {\n",
    "    \"batch_size\": 500,\n",
    "    \"learning_rate\": 0.008,\n",
    "    \"epochs\": 80,\n",
    "    \"query_size\":10000,\n",
    "    \"query_type\": 'coreset',\n",
    "    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \"victim\": { \"data\": CIFAR_10,  \"model_name\": RESNET50 },\n",
    "}\n",
    "\n",
    "parameters = {\n",
    "        \"query_size\": [10000, 20000, 30000, 40000],\n",
    "        \"query_type\": ['coreset', 'coreset_cross'],\n",
    "        \"victim\":[{ \"data\": CIFAR_10, \"model_name\": RESNET50}]\n",
    "}\n",
    "\n",
    "### Run3 - CIFAR10 - A_RESNET34 - V_RESNET50\n",
    "\n",
    "config = {\n",
    "    \"batch_size\": 500,\n",
    "    \"learning_rate\": 0.008,\n",
    "    \"epochs\": 80,\n",
    "    \"query_size\":5000,\n",
    "    \"query_type\": 'random',\n",
    "    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \"victim\": { \"data\": CIFAR_100,  \"model_name\": RESNET_56 },\n",
    "    \"attacker\": RESNET50\n",
    "}\n",
    "\n",
    "parameters = {\n",
    "        \"query_size\": [20000],\n",
    "        \"query_type\": ['random','coreset', 'coreset_cross'],\n",
    "        \"victim\":[{ \"data\": CIFAR_10, \"model_name\": RESNET50}],\n",
    "        \"attacker\": [RESNET34]\n",
    "}\n",
    "\n",
    "### Run4 - A_RESNET34 - Random Query\n",
    "\n",
    "config = {\n",
    "    \"batch_size\": 500,\n",
    "    \"learning_rate\": 0.008,\n",
    "    \"epochs\": 80,\n",
    "    \"query_size\":10000,\n",
    "    \"query_type\": 'random',\n",
    "    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \"victim\": {\"data\": CIFAR_10, \"model_name\": VGG19_BN},\n",
    "    \"attacker\": RESNET34\n",
    "}\n",
    "\n",
    "parameters = {\n",
    "        \"query_size\": [10000, 20000, 30000, 40000, 10000],\n",
    "        \"query_type\": ['random'],\n",
    "        \"victim\":[{ \"data\": CIFAR_10, \"model_name\": VGG19_BN}, \n",
    "                  { \"data\": CIFAR_100, \"model_name\": VGG19_BN}, \n",
    "                  {\"data\": CIFAR_100, \"model_name\": RESNET_56 }],\n",
    "        \"attacker\":[RESNET34]\n",
    "}\n",
    "\n",
    "### Trial Run for coreset\n",
    "\n",
    "config = {\n",
    "    \"batch_size\": 500,\n",
    "    \"learning_rate\": 0.008,\n",
    "    \"epochs\": 10,\n",
    "    \"query_size\":10000,\n",
    "    \"query_type\": 'random',\n",
    "    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \"victim\": {\"data\": CIFAR_10, \"model_name\": VGG19_BN},\n",
    "    \"attacker\": RESNET34\n",
    "}\n",
    "\n",
    "parameters = {\n",
    "        \"query_size\": [50000],\n",
    "        \"query_type\": ['coreset','random'],\n",
    "        \"victim\":[{ \"data\": CIFAR_10, \"model_name\": RESNET50}],\n",
    "        \"attacker\":[RESNET34]\n",
    "}\n",
    "\n",
    "### Run5 - A_RESNET34 - Coreset Query\n",
    "\n",
    "config = {\n",
    "    \"batch_size\": 500,\n",
    "    \"learning_rate\": 0.008,\n",
    "    \"epochs\": 80,\n",
    "    \"query_size\":10000,\n",
    "    \"query_type\": 'random',\n",
    "    \"victim\": { \"data\": CIFAR_10,  \"model_name\": RESNET50 },\n",
    "    \"attacker\": RESNET34,\n",
    "    \"klogits\": 2\n",
    "}\n",
    "\n",
    "parameters = {\n",
    "        \"query_size\": [10000, 20000, 30000, 40000, 50000],\n",
    "        \"query_type\": ['coreset','coreset_cross'],\n",
    "        \"victim\":[{ \"data\": CIFAR_10, \"model_name\": RESNET50},\n",
    "                  { \"data\": CIFAR_10, \"model_name\": VGG19_BN}, \n",
    "                  { \"data\": CIFAR_100, \"model_name\": VGG19_BN}, \n",
    "                  {\"data\": CIFAR_100, \"model_name\": RESNET_56 }],\n",
    "        \"attacker\":[RESNET34],\n",
    "        \"klogits\": [0, 3, 10]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DL_Project",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
