{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/Aishu/dl-model-extraction'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "idQmKzBgZqug"
   },
   "outputs": [],
   "source": [
    "from attacker.training import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case - 3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Case 3 : K-Logits vs Labels\n",
    "    Dataset - Cifar10\n",
    "    klogits - 3, 10\n",
    "    QueryType - coreset\n",
    "    Query Size - 10k, 30k, 50k\n",
    "    Attacker - Resnet34\n",
    "    Victim - Resnet50"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "case3_logits = {\n",
    "        \"query_size\": [20000],\n",
    "        \"query_type\": ['coreset'],\n",
    "        \"victim\":[{ \"data\": CIFAR_10, \"model_name\": RESNET50}],\n",
    "        \"attacker\":[RESNET34],\n",
    "        \"k_logits\": [3, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIL_TESTING_ONLY = {\n",
    "        \"query_size\": [20000],\n",
    "        \"query_type\": ['coreset'],\n",
    "        \"victim\":[{ \"data\": CIFAR_10, \"model_name\": RESNET50}],\n",
    "        \"attacker\":[RESNET34],\n",
    "        \"k_logits\": [10]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## case - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARAMETERS for investigation:\n",
      "{'attacker': ['resnet34'],\n",
      " 'k_logits': [10],\n",
      " 'query_size': [20000],\n",
      " 'query_type': ['coreset'],\n",
      " 'victim': [{'data': 'cifar_10', 'model_name': 'resnet50'}]}\n",
      "---------------------------------------------------------------------------\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Loading queried cifar_10 dataset with resnet50 victim\n",
      "\t- input:10000 queried:10000\n",
      "Sampling using None with query size 10000\n",
      "\t- input:10000 sampled:10000\n",
      "Sampling using coreset with query size 20000\n",
      "\t- input:50000 sampled:20000\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "\tDataset: cifar_10\n",
      "\tVictim: resnet50\tAttacker: resnet34\n",
      "\tQuery Type: coreset\tQuery Size: 20000\tLogits: 10\n",
      "-----------------------------------------------------------------------------\n",
      "Total epochs to run: 150\n",
      "\tepoch 1\n",
      "\t- train_acc 0.22455 train_loss 1.87591\n",
      "\t- test_acc  0.16940 test_loss  7.78076\n",
      "\tepoch 2\n",
      "\t- train_acc 0.25635 train_loss 2.01778\n",
      "\t- test_acc  0.17310 test_loss  34.59591\n",
      "\tepoch 3\n",
      "\t- train_acc 0.19245 train_loss 2.09914\n",
      "\t- test_acc  0.14960 test_loss  8.02153\n",
      "\tepoch 4\n",
      "\t- train_acc 0.22985 train_loss 1.80805\n",
      "\t- test_acc  0.25920 test_loss  2.12584\n",
      "\tepoch 5\n",
      "\t- train_acc 0.27240 train_loss 1.78355\n",
      "\t- test_acc  0.22910 test_loss  2.92441\n",
      "\tepoch 6\n",
      "\t- train_acc 0.28665 train_loss 1.84131\n",
      "\t- test_acc  0.32350 test_loss  1.73104\n",
      "\tepoch 7\n",
      "\t- train_acc 0.29465 train_loss 1.86064\n",
      "\t- test_acc  0.29380 test_loss  2.53896\n",
      "\tepoch 8\n",
      "\t- train_acc 0.30935 train_loss 1.63417\n",
      "\t- test_acc  0.31950 test_loss  1.83631\n",
      "\tepoch 9\n",
      "\t- train_acc 0.34665 train_loss 1.61114\n",
      "\t- test_acc  0.36600 test_loss  1.88402\n",
      "\tepoch 10\n",
      "\t- train_acc 0.35375 train_loss 1.47163\n",
      "\t- test_acc  0.39370 test_loss  1.56247\n",
      "\tepoch 11\n",
      "\t- train_acc 0.36305 train_loss 1.62731\n",
      "\t- test_acc  0.39530 test_loss  1.64774\n",
      "\tepoch 12\n",
      "\t- train_acc 0.37110 train_loss 1.59912\n",
      "\t- test_acc  0.41030 test_loss  1.58508\n",
      "\tepoch 13\n",
      "\t- train_acc 0.39195 train_loss 1.61144\n",
      "\t- test_acc  0.44240 test_loss  1.47931\n",
      "\tepoch 14\n",
      "\t- train_acc 0.40375 train_loss 1.46257\n",
      "\t- test_acc  0.48410 test_loss  1.35071\n",
      "\tepoch 15\n",
      "\t- train_acc 0.42290 train_loss 1.37311\n",
      "\t- test_acc  0.49720 test_loss  1.38653\n",
      "\tepoch 16\n",
      "\t- train_acc 0.44280 train_loss 1.43361\n",
      "\t- test_acc  0.48780 test_loss  1.42852\n",
      "\tepoch 17\n",
      "\t- train_acc 0.45715 train_loss 1.23976\n",
      "\t- test_acc  0.52070 test_loss  1.28859\n",
      "\tepoch 18\n",
      "\t- train_acc 0.48520 train_loss 1.33410\n",
      "\t- test_acc  0.50920 test_loss  1.33401\n",
      "\tepoch 19\n",
      "\t- train_acc 0.49185 train_loss 1.17032\n",
      "\t- test_acc  0.57490 test_loss  1.31704\n",
      "\tepoch 20\n",
      "\t- train_acc 0.51270 train_loss 1.30424\n",
      "\t- test_acc  0.57450 test_loss  1.19116\n",
      "\tepoch 21\n",
      "\t- train_acc 0.51435 train_loss 1.25860\n",
      "\t- test_acc  0.59100 test_loss  1.19530\n",
      "\tepoch 22\n",
      "\t- train_acc 0.53305 train_loss 1.21759\n",
      "\t- test_acc  0.55000 test_loss  1.34982\n",
      "\tepoch 23\n",
      "\t- train_acc 0.54050 train_loss 1.14098\n",
      "\t- test_acc  0.57230 test_loss  1.09418\n",
      "\tepoch 24\n",
      "\t- train_acc 0.56685 train_loss 1.22339\n",
      "\t- test_acc  0.57360 test_loss  1.25350\n",
      "\tepoch 25\n",
      "\t- train_acc 0.57020 train_loss 1.14089\n",
      "\t- test_acc  0.61310 test_loss  1.13498\n",
      "\tepoch 26\n",
      "\t- train_acc 0.58810 train_loss 1.14621\n",
      "\t- test_acc  0.63800 test_loss  1.01168\n",
      "\tepoch 27\n",
      "\t- train_acc 0.60030 train_loss 0.94722\n",
      "\t- test_acc  0.64500 test_loss  0.99906\n",
      "\tepoch 28\n",
      "\t- train_acc 0.61675 train_loss 0.97798\n",
      "\t- test_acc  0.66780 test_loss  0.96198\n",
      "\tepoch 29\n",
      "\t- train_acc 0.63190 train_loss 0.93543\n",
      "\t- test_acc  0.60650 test_loss  1.21581\n",
      "\tepoch 30\n",
      "\t- train_acc 0.65420 train_loss 0.87471\n",
      "\t- test_acc  0.68780 test_loss  0.92772\n",
      "\tepoch 31\n",
      "\t- train_acc 0.66430 train_loss 0.77787\n",
      "\t- test_acc  0.69980 test_loss  0.78874\n",
      "\tepoch 32\n",
      "\t- train_acc 0.66790 train_loss 0.84006\n",
      "\t- test_acc  0.71360 test_loss  0.82410\n",
      "\tepoch 33\n",
      "\t- train_acc 0.68315 train_loss 0.86527\n",
      "\t- test_acc  0.71440 test_loss  0.85171\n",
      "\tepoch 34\n",
      "\t- train_acc 0.69615 train_loss 0.80540\n",
      "\t- test_acc  0.72050 test_loss  0.89445\n",
      "\tepoch 35\n",
      "\t- train_acc 0.70650 train_loss 0.85712\n",
      "\t- test_acc  0.68280 test_loss  0.93714\n",
      "\tepoch 36\n",
      "\t- train_acc 0.72470 train_loss 0.65768\n",
      "\t- test_acc  0.71780 test_loss  0.80858\n",
      "\tepoch 37\n",
      "\t- train_acc 0.72740 train_loss 0.67661\n",
      "\t- test_acc  0.73190 test_loss  0.77737\n",
      "\tepoch 38\n",
      "\t- train_acc 0.74190 train_loss 0.64832\n",
      "\t- test_acc  0.73530 test_loss  0.72433\n",
      "\tepoch 39\n",
      "\t- train_acc 0.75165 train_loss 0.68229\n",
      "\t- test_acc  0.75140 test_loss  0.82305\n",
      "\tepoch 40\n",
      "\t- train_acc 0.75730 train_loss 0.63971\n",
      "\t- test_acc  0.76960 test_loss  0.73056\n",
      "\tepoch 41\n",
      "\t- train_acc 0.78035 train_loss 0.53208\n",
      "\t- test_acc  0.73460 test_loss  0.72596\n",
      "\tepoch 42\n",
      "\t- train_acc 0.78455 train_loss 0.61696\n",
      "\t- test_acc  0.75750 test_loss  0.76987\n",
      "\tepoch 43\n",
      "\t- train_acc 0.80095 train_loss 0.54678\n",
      "\t- test_acc  0.76810 test_loss  0.56589\n",
      "\tepoch 44\n",
      "\t- train_acc 0.80760 train_loss 0.43256\n",
      "\t- test_acc  0.76690 test_loss  0.70688\n",
      "\tepoch 45\n",
      "\t- train_acc 0.81400 train_loss 0.47631\n",
      "\t- test_acc  0.77770 test_loss  0.66331\n",
      "\tepoch 46\n",
      "\t- train_acc 0.83665 train_loss 0.39454\n",
      "\t- test_acc  0.78330 test_loss  0.63076\n",
      "\tepoch 47\n",
      "\t- train_acc 0.84400 train_loss 0.39671\n",
      "\t- test_acc  0.78160 test_loss  0.61149\n",
      "\tepoch 48\n",
      "\t- train_acc 0.86330 train_loss 0.41712\n",
      "\t- test_acc  0.79260 test_loss  0.62171\n",
      "\tepoch 49\n",
      "\t- train_acc 0.87055 train_loss 0.36074\n",
      "\t- test_acc  0.79020 test_loss  0.58293\n",
      "\tepoch 50\n",
      "\t- train_acc 0.88030 train_loss 0.31779\n",
      "\t- test_acc  0.79910 test_loss  0.69886\n",
      "\tepoch 51\n",
      "\t 9000 ..."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3054/1553149230.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minvestigate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIL_TESTING_ONLY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/dl-model-extraction/attacker/training.py\u001b[0m in \u001b[0;36minvestigate\u001b[0;34m(parameters, verbose, seed)\u001b[0m\n\u001b[1;32m    197\u001b[0m                         \u001b[0;31m# train attacker model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                         attacker, attacker_result = attacker_training(attacker, querytrainloader, querytestloader, \n\u001b[0;32m--> 199\u001b[0;31m                                                             victim_type, outputs, k=k, verbose=verbose)\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dl-model-extraction/attacker/training.py\u001b[0m in \u001b[0;36mattacker_training\u001b[0;34m(attacker_model, trainloader, testloader, victim_type, num_classes, k, verbose)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0mtrain_loss_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mtrain_loss_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m                 \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    151\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                    \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                    maximize=group['maximize'])\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "investigate(TRAIL_TESTING_ONLY, verbose=True, seed=42)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "investigate(config[\"base\"], seed=42) #to run default config"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DL_Project",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
